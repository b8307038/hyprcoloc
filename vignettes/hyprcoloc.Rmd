---
title: "HyPrColoc"
author: "Christopher Foley & James Staley"
date: "9/05/2019"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{hyprcoloc}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



## Introduction

HyPrColoc is Bayesian divisive clustering algorithm for identifying clusters of traits which colocalize at distinct causal variants in a genomic region. The default algorithm can identify clusters of putatively colocalized traits, within a vast collection of traits, e.g. 1000s, quickly. For each set of putatively colocalized traits, the algorithm outputs: the names of the traits, the posterior probability of colocalization, the location of the shared putatively causal variant and a ‘fine-mapping’ probability to quantify evidence supporting the candidate causal variant being the causal variant. 

Traits can be either continuous, e.g. blood pressure, or discrete, e.g. a disease. Basic analyses require information on the summarized effect estimates (i.e. estimated regression coefficients) and their corresponding standard errors, for each snp in the genomic region and each trait under consideration. These should be entered as numeric matrices. If the traits are measured in non-independent studies (i.e. those containing overlapping participants) analyses can be adjusted to account for this. To do this three additional matrices are required: (i) the pair-wise marginal correlations between the traits; (ii) the pair-wise LD estimates between the snps in the region and; (iii) the pair-wise estimates of the proportion of sample overlap between study participants. We recommend reading our note (below and in more detail our paper) on adjusting analyses to account for correlated summary data and a-priori trait correlation before doing so in your analyses. 

### Installation

```{r, echo=F}
options(warn=-1)
```

```{r, eval=F}
install.packages("devtools", repos='http://cran.us.r-project.org')
library(devtools)
install_github("jrs95/hyprcoloc")
```

## Getting started

In the first part of this exercise we begin by loading the package and some data needed to run analyses using HyPrColoc. For a given region, a standard analysis requires data from two matrices, of equal size, denoting: (i) a matrix of effect estimates (betas), with the columns denoting the study traits and rows the snps, and; (ii) a matrix of corresponding standard errors (ses).

```{r}
library(hyprcoloc)
betas <- hyprcoloc::test.betas
head(betas)
ses <- hyprcoloc::test.ses
head(ses)
```


### Basic set-up: assuming independce between studies 

By default HyPrColoc assumes that each trait is measured in a distinct study, i.e. that the participants do not overlap between studies, so that between study estimates of regression coefficients (betas) are independent. The HyPrColoc function will automatically employ the Bayesian divisive clustering algorithm to identify clusters of colocalized traits. Each study (/trait) will be assigned a name corresponding to their column position and similarly the snps will be assigned names according to row position. To input trait and snp labels we make use of the "trait.names" and "snp.id" variables, e.g.      

```{r}
traits <- paste0("T", 1:dim(betas)[2])
rsid <- rownames(betas)
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid)
res
```

From the above output we see that, for each iteration of the algorithm, HyPrColoc returns:

(i) a cluster of putatively colocalized traits
(ii) the posterior probability that these traits are colocalized
(iii) the 'regional association' probability* (which is always > the posterior probability)
(iv) a candidate causal variant explaining the shared association 
(v) the proportion of the posterior probability explained by this variant (which represents the HyPrColoc multi-trait fine-mapping probability). 

*Note that a 'large' regional association probability is evidence that one or more snps in the region have shared associations across the traits, the result is similar to a PHeWAS (Phenome-wide association study) and we discuss this more later. The results above show that in three iterations HyPrColoc identified that traits 1-5 form a cluster of colocalized traits, traits 6-8 form a separate cluster of colocalized traits and finally that traits 9 and 10 also colocalize. We see that the cluster of traits 1-5 have a posterior probability of $1$ of being colocaized, hence the regional association probability is also $1$ and that the candidate snp rs11591147 explains 100\% of the posterior. Thus, there is very strong support that traits 1-5 colocalize and that rs11591147 be taken as the candidate causal snp in the region. On the other hand, traits 9 and 10 show strong evidence of colocalizing, having a posterior probability of $0.9$, but there is weak evidence to support rs7524677 as the causal snp in the region. This example helps to illustrate that: while a cluster of traits can show strong evidence of colocalization the snp most likely to explain colocalization between the traits can be vague.

#### Choosing a subset of traits to analyze

We can choose to assess evidence of colocalization across a subset of the traits. For example, let's suppose interest lies in assessing the first two traits only, in this situation we make use of the "trait.subset" variable, e.g.

```{r}
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, trait.subset = c("T1","T2"));
res
```

#### Labelling a trait as either continuous or binary in analyses

For technical reasons, analyses have a dependence on whether a trait is continuous or binary. To let HyPrColoc know which traits are continuous (coded 0) or binary (coded 1) we use the "binary.outcome" variable. For example, suppose the first three traits are binary, then we type 

```{r}
binary.traits = c(1,1,1,rep(0,dim(betas)[2]-3));
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, binary.outcomes = binary.traits);
res
```

### The Bayesian divisive clustering algorithm

The Bayesian divisive clustering algorithm identifies clusters of colocalized traits in the sample. The algorithm is automatically used when all traits are identified as not sharing a causal variant. For each iteration of the algorithm, the goal is to identify a subset of traits with the greatest evidence of colocalization. HyPrColoc does this using one of two (user defined) approaches: (i) the regional or (ii) alignment selection criterion. The regional selection criterion is computed from a collection of hypotheses which assume that all traits do not colocalize because one of the traits does not have a causal variant in the region. The alignment selection criterion, however, is computed from hypotheses which assume that all traits do not colocalize because one of the traits has a causal variant elsewhere in the region. The alignment selection process searches a much larger amount of the causal configuration space and is thus more computationally expensive (but potentially more robust) than regional selection. Typically, both strategies perform similarly and we therefore chose the regional selection as the default setting. 


#### Assessing differences between the Bayesian divisive clustering criteria

The regional selection criterion:   

```{r}
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, bb.selection = "regional");
res
```

The alignment selection criterion:   

```{r}
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, bb.selection = "align");
res
```

Hence, in our test dataset there is no difference in the results when using either the reginoal or the alignment selection criterion. 


#### Switching the algorithm off

We can choose to switch the Bayesian divisive clustering algorithm off and assess whether all traits colocalize. 

```{r}
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, bb.alg = FALSE);
res
```


## Mapping pleiotropy: a quick and robust alternative to PHeWAS 

The regional association can be used as an alternative to a PHeWAS assessment. To see this, we first discuss how the regional association probability is computed.

For each of $Q$ snps in the region, we compute the the probability that a snp is associated with all traits and divide this by the sum of the probabilities that: one of the $Q$ snps is associated with all traits; all but one trait; all but two traits and so on... Consequently, a 'large' (close to 1) regional association probability indicates that one or more snps in the region share an association with all traits. Small values indicate that there is not a snp in the region associated with all traits, the divisive clustering algorithm with then attempt to identify a subset of traits which have a regional association probability above a user defined threshold (default $P_{R}^{\ast}= 0.5$). 

The regional association probability aggregates evidence from each snp separately, hence there is no restriction on the number of causal variants in the region. This means that large values can arise in a number of ways which we now describe. A large regional association probability can occur when all traits have a single causal variant in the region and either: (i) the causal variant is shared across all traits or; (ii) at least one trait has a distinct causal variant and the distinct causal variants are on strong LD with one another. Alternatively, a large probability can occur because one or more traits have multiple causal variants in the region and either: (i) one or more causal variants are shared across all traits or; (ii) at least one trait has a distinct causal variant, but each trait has a causal variant in strong LD with one of the causal variants associated with all other traits.

```{r}
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, bb.selection = "reg.only", reg.thresh = 0.9);
res
```

The results indicate that there exists one or more snps that share associations with traits 1-5, which is expected from our previous colocalization analysis. We note that there exists at least one snp which is associated with traits 6-10 and that the most likely snp is rs12117612, which explains 31.4% of the regional association probability. This contrasts with the results from our earlier colocalization assessment which indicated that traits 6-10 do not all colocalize, highlighting some distinction between shared genetic associations between traits and multi-trait colocalization at a single causal variant. 


## An analysis protocol: assessing stability of clusters via a sensitivity analysis 

It is important that users of the software ackowledge that the performance of HyPrColoc is particularly dependendant on the choice of prior configuration probabilities used (and any associated hyper-parameters) as well as the choice of regional and alignment thresholds, as these combine to quantify a lower bound with which we accept that a cluster of traits colocalize (i.e. clusters are identified when $P_RP_{A}\geq P^{\ast}_{R}P^{\ast}_{A}$). In some situations this senstivity might be modest, whilst in others it might be large. For example, through extensive simulations, we note that in the analysis of large numbers of traits, using only the default algorithm settings, can regularly result in the trait clusters containing (typically only a single) false positive. Avoiding this issue is complex as it is unlikely that there exists a one-size-fits-all approach to setting the prior configuration probabilities and likewise the regional and alignment threshold parameters. Hence, to go someway to addressing these issues we provide an analysis protocol template, to assess the strength of any conclusions. 

### Assessing sensitivity to changes in the prior configuration parameters 

An important feature of the HyPrColoc software is that it allows for some sensitivity to the choice of causal configuration priors to be assessed. Two prior choices are presented: (i) conditionally uniform priors, which assumes that all causal configurations relating to a given hypotheses are equally likely, and; (ii) variant specific prioris, which, for each variant, focuses on tuning the probability that a variant is colocalized with a subset of traits, for all possible subsets.    


##### Conditionally uniform configuration priors:   

The conditionally uniform prior framework assigns all non-null hypotheses (i.e. those in which at least one trat have a causal variant in the region) the same probaility. Note that this does not mean that all causal configuration prior probailities are the same, mearly that the prior probabilities of each causal configuration associated with a distinct hypothesis must add up to the same amount between hypothesis. This means that the conditionally uniform prior strategy benefits from automatically adjusting to both the numbers of traits and the number of snps included in analyses, i.e. the configuration priors are a function of the number of traits and snps.  The approach does require specificying one parameter "prior.1", which is the ratio of the prior probability of a any hypothesis in which at least one trait has a causal variant in the region ($P(H_{j})$) divided by the null-hypothesis that no traits have a causal variant in the region $P(H_{0})$, i.e. $prior.1 = \frac{H_{j}}{H_{0}}$.  By default, we set $prior.1=10^{-4}$, so that any alternative hypothesis is 10000 times less likely a-priori relative to the null hypothesis. The we choose this value as the role of "prior.1" can be considered similarly to the role of $p1$ in the widely used sofwtare "COLOC".  We now explore sensitivity of our results to the specification of "prior.1" across a wide range of initializations,   

```{r}
prior.options = c(1e-4, 1e-10, 1e-25, 1e-100);
for(i in prior.options){
  res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, uniform.priors = TRUE, prior.1 = i, reg.steps = 2);
  print(paste0("prior.1 = ",i));
  print(res);
  }
```

Hence, when analysing the sample dataset using the conditionally uniform prior set-up, the results from HyPrColoc have a weak dependence on the specification of "prior.1". Moreover, setting $prior.1 \in [10^{-4}, 10^{-20}]$ the colocalization results do not change. It should however be noted that the posterior probabilities associated with each cluster of colocalized traits is markedly larger than those computed using the variant specific prior configuration set-up.


##### Variant specific configuration priors (default):   

The variant specific prior configuration set-up is a multi-trait extention to the configuration priors used in COLOC. Users familiar with this software will no doubt know that the performance of COLOC is sensitive to the choice of configuration prior parameters and, when using a multi-trait extention of this prior set-up, we will see that HyPrColoc is also sensitive to the choice of prior parameters. However, as HyPrColoc jointly assesses colocalization across multiple traits, the multi-trait assessment provides an ideal platform to assess any prior senstivity. In particular, by increasing (alternatively decreasing) the prior parameter values we can assess how stable the clusters of putatively colocalized traits are, i.e. we can assess the overlap of the clusters of putatively colocalized traits returned from two separate analyses each of which uses a distinct value for the prior probability of colocalization. The general principle 

can be used to  advantage   To use this strategy, we require the specification of two parameters: "prior.1" denoting the probability that a snp is associated with a songle trait and "prior.2" such that $1-prior.2$ is the prior probaility that a snp is associated with an additonal trait given that it is associated with at least one trait,  $1-prior.2^2$ is the prior probability that the snp is associated with a third trait given it is associated with two other traits and so on... By default $prior.1 = 10^{-4}$ and $prior.2 = 0.98$, hence the prior probability that any snp is a ssociated with a trait is 1 in 10000, matching that used in COLOC; the prior probability that the snp is associated with a second trait, conditional on association with one trait, is 1 in 50; the prior probaility that it is associated with a third trait given association with two other traits is just under 1 in 25; and so on... Notice that the marginal probability that a snp is associated with an increasing number of traits is always small and decreasing, e.g. $\frac{1}{10^{4}}*\frac{1}{50}*\frac{1}{25}\dots$  

```{r}
prior1.options = c(1e-4);
prior2.options = c(0.95, 0.98, 0.99, 0.999);
for(i in prior1.options){
  for(j in prior2.options){
  res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, uniform.priors = FALSE, prior.1 = i, prior.2 = j);
  print(c(paste0("prior.1 = ",i), paste0("prior.2 = ",j)));
  print(res);
  }
}
```


We notice that results deduced under the variant specific priors are   

##### Evidential strength and the regional and alignment thresholds  

The default regional $P_{R}^{\ast}$ and alignment $P_{A}^{\ast}$ paramter thresholds are dependent on the choice of configuration prior. The default regional threshold and alignment thresholds using conditionally uniform (CU) configuration priors are $P_R^{\ast}=P_{A}^{\ast}=0.7$ whereas for variant specific (VS) priors the thresholds are set to  $P_R^{\ast}=P_{A}^{\ast}=0.5$. Accordingly, the algorithm will deduce that a set of traits are colocalized when  $P_RP_{A}\geq 0.49$ using CU priors and $P_RP_{A}\geq 0.25$ when using VS priors. We do this because CU priors tend to have a slightly increased false positive rate. Note, these parameter choices are a consequence of extensive testing in simulation scenarios, aiming to maximise the true detection rate whilst minimising the number of false positives. We therefore DO NOT recommend reducing either of these parameters. The defaults should be viewed as lower bounds.

If interest lies in identifying sets of colocalized traits above a certain posterior probability, more stringent regional and alignment threshold parameters can be chosen, e.g.

```{r}
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, bb.selection = "regional", uniform.priors = FALSE, reg.thresh = 0.95, align.thresh = 0.95);
res
```

## Analysing correlated traits

When interest lies in identifying colocalization across a set of traits whose summary data are correlated (due to overlapping participants) three additional pieces of information are required: (i) a matrix containing the putative correlation between the traits; (ii) a matrix containing the LD between the snps in the region and; (iii) a matrix containing the proportion of shared participants between each pair of studies. Note the matrix of overlapping sample proportions has diagonal elements set to 1 and off diagonal elements $(i,j)$ denote the proportion of overlap between the $i$'th and $j$'th studies, i.e. if N denotes the total number of overlapping participants and $\{N_{i},N_{j}\}$ denote the numbers of participants in the $i$'th and $j$'th studies respectively, then $N/\left(N_{i}N_{j}\right)$ is the  $(i,j)=(j,i)$ element. As sample overlap information may not always be available, the HyPrColoc default assumes all studies have the same participants.   

#### Important, before going further...

Should analyses be adjusted for observed correlation between study summary data?

It is our recommendation that users first consider whether this is necessary. There are several points to consider. Firstly, traits which are strongly correlated are in general more likely to colocalize. This has two important consequences: (i) whilst special exceptions exist, generally the a-priori probability of colocalization between two strongly correlated traits is necessarily larger than two traits that are weakly correlated, analyses which ignore this are less likely to capture the largest set of traits which are truley colocalized and; (ii) when a subset of traits which are truley colocalized are identified, one or more of the correlated traits can be wrongly identified as not colocalizing due to mathematical subtleties in the processing of the correlation matrices and NOT because of  some underlying biological importance, this has serious consequences on how we draw biological conclusions from correlation adjusted analyses. Secondly, analysing correlated summary data requires much more computing power and time, owing to many rounds of expensive matrix inversion. Finally, in our extensive testing, when wronly assuming independence between study data we found little to no impact on the false positive detection rate in contrast to when correctly assuming independence.  

#### Analysing correlated traits, continued... 

Our command line tool can automatically compute trait correlation (using a tetrachoric correlation technique) and LD information. However, the R-package requires users to have this information to hand. 

```{r}
trait.cor <- hyprcoloc::test.corr
ld.matrix <- hyprcoloc::test.ld
sample.overlap = matrix(1, dim(betas)[2], dim(betas)[2]) # default assumption, hence presented for clarity
```

##### Variant specific priors

```{r}
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, trait.cor = trait.cor, ld.matrix = ld.matrix, sample.overlap = sample.overlap, uniform.priors = FALSE);
res
```

##### Conditionally uniform priors

```{r}
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid, trait.cor = trait.cor, ld.matrix = ld.matrix, sample.overlap = sample.overlap, uniform.priors = TRUE);
res
```

##### Assuming independence (which correctly captures the data generating model)

```{r}
res <- hyprcoloc(betas, ses, trait.names=traits, snp.id=rsid);
res
```
